\documentclass[11pt,a4paper]{article}
\usepackage[hyperref]{acl2025}
\usepackage{times}
\usepackage{latexsym}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{booktabs}
\usepackage{tikz}
\usetikzlibrary{arrows.meta, positioning}
\renewcommand{\UrlFont}{\ttfamily\small}

% Additional packages for tables and float control
\usepackage{tabularx}
\usepackage{placeins}
\usepackage{caption}
\captionsetup[table]{skip=6pt}

\title{Multilingual Clinical Dialogue Summarization and Structured Information Extraction using Qwen-1.5B with LoRA Adapters}

\author{
Team XYZ\thanks{\hspace{0.2cm}Final Submission for NLP-AI4Health 2025 Shared Task.} \\
Institution / Organization \\
\texttt{team.email@example.com}
}

\date{}

\begin{document}
\maketitle

\begin{abstract}
This paper describes our submission to the NLP-AI4Health 2025 Shared Task on multilingual clinical dialogue summarization and structured information extraction.
Our system is based on Qwen-1.5B Instruct fine-tuned with LoRA adapters for parameter-efficient adaptation.
The pipeline produces (i) concise English summaries, (ii) schema-aligned JSON outputs, and (iii) multilingual Q\&A responses.
Compared to our baseline (Gemma-1B), the Qwen-based approach substantially improves summary fluency, factual completeness, and JSON field coverage while maintaining efficiency within constrained GPU resources.
\end{abstract}

\section{Introduction}
The 2025 Shared Task on multilingual clinical dialogue summarization challenges systems to process doctor--patient conversations across ten languages and output three modalities: summaries, structured records, and Q\&A responses.
We present a LoRA-adapted Qwen-1.5B pipeline optimized for factual summarization and schema-based information extraction, designed to handle multilingual inputs efficiently under limited hardware conditions.

\section{System Architecture and Approach}

\begin{figure*}[t]
\centering
\begin{tikzpicture}[
    node distance=1.4cm and 1.4cm,
    every node/.style={font=\small, align=center},
    box/.style={rectangle, rounded corners, draw=black, thick, fill=gray!10, text width=3cm, minimum height=1cm, align=center},
    arrow/.style={thick,->,>=stealth}
]

\node[box, fill=blue!10] (input) {Multilingual \\ Doctor--Patient Dialogue};
\node[box, fill=orange!10, right=of input] (token) {Qwen Tokenizer \\ (32k context clipping)};
\node[box, fill=green!10, right=of token] (summary) {Stage 1: English Summary};
\node[box, fill=yellow!10, right=of summary] (json) {Stage 2: Field-by-Field \\ JSON Extraction};
\node[box, fill=red!10, right=of json] (qna) {Stage 3: Multilingual \\ Q\&A Response};
\node[box, fill=purple!10, right=of qna] (output) {Final Outputs \\ (Summary, JSON, Q\&A)};

\draw[arrow] (input) -- (token);
\draw[arrow] (token) -- (summary);
\draw[arrow] (summary) -- (json);
\draw[arrow] (json) -- (qna);
\draw[arrow] (qna) -- (output);

\end{tikzpicture}
\caption{Overview of the multilingual summarization and extraction pipeline.}
\label{fig:pipeline}
\end{figure*}

\subsection{Model Configuration}
We used Qwen-1.5B Instruct quantized to 4-bit NF4 precision via \texttt{BitsAndBytes}.
LoRA adapters were trained with rank $r=8$, $\alpha=32$, dropout $0.05$, and target modules \texttt{q\_proj} and \texttt{v\_proj}.
Training used the AdamW optimizer ($2\times10^{-4}$ learning rate, cosine decay).
Gradient checkpointing and mixed precision allowed training within 60GB RAM and 32×V100 GPUs.

\subsection{Inference Pipeline}
Each language’s dialogues were processed independently with checkpoint resumption support.
The inference proceeds through:
\begin{enumerate}
    \item \textbf{Summary Generation:} Produce an English summary ending with sentinel token \texttt{<<END>>}.
    \item \textbf{Structured Extraction:} Populate each JSON field by querying the model separately.
    \item \textbf{Multilingual Q\&A:} Generate answers in the dialogue’s original language.
\end{enumerate}
Greedy decoding (\texttt{do\_sample=False}) ensures stable, deterministic outputs across runs.

\FloatBarrier
\subsection{Field-by-Field JSON Extraction}
Instead of prompting the model to generate the entire schema, each JSON field is treated as a \textit{question–answer} task.
For example:
\begin{quote}
\small
Q: What is the patient's chief complaint? \\
A: Persistent throat discomfort and hoarseness for two months.
\end{quote}

Each question is asked separately with the dialogue and its summary as context.
This modular design improved JSON field coverage $\sim$3× compared to single-shot JSON prompting and allowed missing fields to be regenerated individually.

\begin{table}[t]
\centering
\small
\setlength{\tabcolsep}{4pt}
\begin{tabular}{lp{5.8cm}}
\toprule
\textbf{Field} & \textbf{Example Q--A Pair (≤12 words)} \\
\midrule
Chief Complaint & Q: What is the patient’s chief complaint? \newline
A: Persistent throat discomfort and hoarseness for two months. \\
Past Medical History & Q: Summarize past medical history. \newline
A: No major illnesses reported previously. \\
Management Plan & Q: Summarize management plan. \newline
A: Schedule biopsy and CT scan; smoking cessation counselling. \\
\bottomrule
\end{tabular}
\caption{Examples of field-level question–answer pairs for JSON extraction.}
\label{tab:jsonqa}
\end{table}

\FloatBarrier

\section{Dataset and Preprocessing}
We used the multilingual clinical dialogue dataset provided by the organizers, covering 10 languages: English, Hindi, Gujarati, Tamil, Telugu, Marathi, Kannada, Bangla, Assamese, and Dogri.
Dialogues were concatenated turn-wise and normalized for whitespace and encoding.
Native Indic scripts were retained, avoiding romanization to preserve token integrity for Qwen’s multilingual tokenizer.

\section{Experimental Results and Analysis}
\subsection{Baselines}
An initial Gemma-1B fine-tuned system was submitted but exhibited incomplete structured outputs and low multilingual fluency.
The final Qwen-LoRA system replaced it, leveraging checkpoint resumption and selective language skipping to address infrastructure limitations.

\subsection{Evaluation Results}

Table~\ref{tab:main-results} presents official results across subtasks:
QnA (macro F1), Summary\_Text (ROUGE-L and BERTScore F1), and Summary\_KNV (key–value field F1).

\begin{table}[t]
\centering
\small
\setlength{\tabcolsep}{5pt}
\begin{tabular}{lcccc}
\toprule
\textbf{Lang} & \textbf{QnA F1} & \textbf{ROUGE-L} & \textbf{BERT-F1} & \textbf{KNV F1} \\
\midrule
Marathi  & 0.228 & 0.169 & 0.811 & 0.302 \\
Kannada  & 0.471 & 0.169 & 0.825 & 0.272 \\
Gujarati & 0.496 & 0.170 & 0.839 & 0.269 \\
English  & \textbf{0.674} & \textbf{0.191} & 0.835 & \textbf{0.335} \\
Telugu   & 0.345 & 0.179 & 0.834 & 0.263 \\
Tamil    & 0.442 & 0.182 & \textbf{0.838} & 0.297 \\
Bangla   & 0.334 & 0.185 & 0.822 & 0.290 \\
Hindi    & 0.618 & 0.176 & 0.836 & 0.344 \\
Assamese & 0.533 & 0.181 & 0.834 & 0.288 \\
\midrule
\textbf{Macro} & \textbf{0.460} & \textbf{0.178} & \textbf{0.830} & \textbf{0.296} \\
\bottomrule
\end{tabular}
\caption{Official evaluation results. QnA: macro F1. Summary\_Text: ROUGE-L F1 (lexical) and BERTScore F1 (semantic). Summary\_KNV: field-level key–value F1.}
\label{tab:main-results}
\end{table}

\paragraph{Findings.}
(\emph{i}) \textbf{QnA:} Average F1 = 0.46, with English (0.67), Hindi (0.62), and Assamese (0.53) strongest.
Low exact-match but high semantic alignment indicates paraphrastic correctness.  
(\emph{ii}) \textbf{Summaries:} ROUGE-L averages 0.178, while BERTScore F1 remains high (0.83 macro), showing strong semantic fidelity despite limited lexical overlap.  
(\emph{iii}) \textbf{JSON Extraction:} Field-by-field design achieves macro F1 = 0.296, outperforming single-pass baselines in completeness and structural validity.

\section{Discussion}
Key challenges included limited GPU access, frequent checkpoint interruptions, and language imbalance for low-resource pairs (Dogri, Assamese).
Our design enabled selective skipping of completed languages and resumable training to maximize throughput.
Empirically, modular JSON generation increased field completion threefold and improved robustness across multilingual dialogues.

\section{Conclusion}
We presented a multilingual clinical dialogue summarization and structured extraction system based on Qwen-1.5B with LoRA adapters.
The approach balances factual precision, cross-lingual generalization, and computational efficiency.
Future work will explore retrieval-augmented factual grounding, factual consistency scoring, and scaling to larger Qwen variants.

\vspace{0.3cm}
\noindent\textbf{Acknowledgements:} We thank the NLP-AI4Health 2025 organizers for the dataset, infrastructure, and evaluation support.

\end{document}
