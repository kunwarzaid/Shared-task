import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import re

# ============================================================
# 1Ô∏è‚É£ LOAD & CLEAN CSV
# ============================================================
csv_path = "Shared_task_results(Zaid).csv"

raw_preview = pd.read_csv(csv_path, nrows=5, header=None)
print("üîç Header preview (first 5 rows):")
print(raw_preview.head())

# find header row containing 'Language'
lang_row_idx = raw_preview.apply(lambda r: r.astype(str).str.contains("Language", case=False, na=False)).any(axis=1)
lang_row = list(np.where(lang_row_idx)[0])
if not lang_row:
    raise ValueError("‚ùå Could not find 'Language' in the first 5 rows.")
lang_header_row = lang_row[0]
print(f"‚úÖ Detected header row containing 'Language': Row {lang_header_row}")

header_rows = list(range(lang_header_row + 1))
df = pd.read_csv(csv_path, header=header_rows)

# flatten multi-index columns
if isinstance(df.columns, pd.MultiIndex):
    df.columns = [
        "_".join([str(x).strip() for x in c if str(x).lower() != "nan" and x.strip() != ""])
        for c in df.columns
    ]
else:
    df.columns = df.columns.astype(str)

# clean column names
def clean_col(col):
    col = re.sub(r"Unnamed:_\d+_level_\d+_", "", col)
    col = col.replace(" ", "_").replace("__", "_").strip("_")
    return col.lower()

df.columns = [clean_col(c) for c in df.columns]

# detect Language column
lang_candidates = [c for c in df.columns if "language" in c.lower()]
lang_col = lang_candidates[0] if lang_candidates else df.columns[0]
df.rename(columns={lang_col: "Language"}, inplace=True)

print(f"‚úÖ Using '{lang_col}' as Language column.")
print("‚úÖ Cleaned column sample:", df.columns[:10].tolist(), "\n")

# ============================================================
# 2Ô∏è‚É£ DETECT METRICS
# ============================================================
metrics = {
    "f1": [c for c in df.columns if "f1" in c and "bertscore" not in c],
    "bertscore_f1": [c for c in df.columns if "bertscore_f1" in c],
    "cometscore": [c for c in df.columns if "cometscore" in c],
}

for k, v in metrics.items():
    print(f"‚úÖ {k} columns: {len(v)}")

# ============================================================
# 3Ô∏è‚É£ DEFINE TASKS
# ============================================================
tasks = {
    "QnA": [c for c in metrics["f1"] if "qna" in c],
    "Summary (Text)": [c for c in metrics["f1"] if "summary_text" in c],
    "Summary (JSON)": [c for c in metrics["f1"] if "summary_knv" in c],
}

# ============================================================
# 4Ô∏è‚É£ COMPUTE TASK-WISE AVERAGES
# ============================================================
task_avgs = {}
for task_name, f1_cols in tasks.items():
    task_avgs[task_name] = {}
    # F1 per task
    task_avgs[task_name]["f1"] = df[f1_cols].mean(axis=1).mean() if f1_cols else np.nan
    # Global metrics
    for metric in ["bertscore_f1", "cometscore"]:
        cols = metrics[metric]
        task_avgs[task_name][metric] = df[cols].mean(axis=1).mean() if cols else np.nan

print("\n‚úÖ Task-wise averages computed:")
for t, vals in task_avgs.items():
    print(f"  {t}: " + ", ".join([f"{m}={vals[m]:.3f}" for m in vals]))

# ============================================================
# 5Ô∏è‚É£ PLOT TASK-WISE PERFORMANCE
# ============================================================
task_names = list(task_avgs.keys())
metric_colors = {"f1": "#4e79a7", "bertscore_f1": "#59a14f", "cometscore": "#e15759"}

x = np.arange(len(task_names))
width = 0.25

plt.figure(figsize=(8, 5))
for i, metric in enumerate(["f1", "bertscore_f1", "cometscore"]):
    vals = [task_avgs[t][metric] for t in task_names]
    plt.bar(x + (i - 1) * width, vals, width, label=metric.replace("_f1", "").upper(), color=metric_colors[metric])
    for j, v in enumerate(vals):
        plt.text(x[j] + (i - 1) * width, v + 0.01, f"{v:.2f}", ha="center", fontsize=8)

plt.ylabel("Score", fontsize=12)
plt.xticks(x, task_names, fontsize=11)
plt.ylim(0, 1)
plt.title("Average Performance Across Tasks", fontsize=14, weight="bold")
plt.legend(frameon=False, loc="lower right")
plt.tight_layout()
plt.savefig("qwen_taskwise_performance_unified.png", dpi=300)
plt.show()

# ============================================================
# 6Ô∏è‚É£ LANGUAGE-WISE PERFORMANCE
# ============================================================
language_scores = df[["Language"]].copy()
for metric, cols in metrics.items():
    language_scores[metric] = df[cols].mean(axis=1) if cols else np.nan

languages = language_scores["Language"].tolist()
x = np.arange(len(languages))
width = 0.25

plt.figure(figsize=(10, 6))
for i, metric in enumerate(["f1", "bertscore_f1", "cometscore"]):
    vals = language_scores[metric].tolist()
    plt.bar(x + (i - 1) * width, vals, width, label=metric.replace("_f1", "").upper(), color=metric_colors[metric])
    for j, v in enumerate(vals):
        plt.text(x[j] + (i - 1) * width, v + 0.005, f"{v:.2f}", ha="center", fontsize=8)

plt.ylabel("Score", fontsize=12)
plt.xticks(x, languages, rotation=45, ha="right", fontsize=10)
plt.ylim(0, 1)
plt.title("Language-wise Performance Across Metrics", fontsize=14, weight="bold")
plt.legend(frameon=False, loc="upper right")
plt.tight_layout()
plt.savefig("qwen_languagewise_performance_unified.png", dpi=300)
plt.show()

# ============================================================
# 7Ô∏è‚É£ LATEX TABLE
# ============================================================
f1_vals = language_scores["f1"].tolist()
bert_vals = language_scores["bertscore_f1"].tolist()
comet_vals = language_scores["cometscore"].tolist()

avg_f1 = np.nanmean(f1_vals)
avg_bert = np.nanmean(bert_vals)
avg_comet = np.nanmean(comet_vals)

print("\n‚úÖ Overall Averages:")
print(f"  F1: {avg_f1:.3f} | BERTScore: {avg_bert:.3f} | COMET: {avg_comet:.3f}")

best_f1_lang = languages[np.nanargmax(f1_vals)]
best_bert_lang = languages[np.nanargmax(bert_vals)]
best_comet_lang = languages[np.nanargmax(comet_vals)]

latex_table = "\\begin{table}[h]\n\\centering\n\\small\n"
latex_table += "\\begin{tabular}{lccc}\n\\toprule\n"
latex_table += "Language & F1 & BERTScore & COMET \\\\\n\\midrule\n"

for lang, f, b, c in zip(languages, f1_vals, bert_vals, comet_vals):
    f_str = f"\\textbf{{{f:.3f}}}" if lang == best_f1_lang else f"{f:.3f}"
    b_str = f"\\textbf{{{b:.3f}}}" if lang == best_bert_lang else f"{b:.3f}"
    c_str = f"\\textbf{{{c:.3f}}}" if lang == best_comet_lang else f"{c:.3f}"
    latex_table += f"{lang} & {f_str} & {b_str} & {c_str} \\\\\n"

latex_table += "\\midrule\n"
latex_table += f"\\textbf{{Average}} & {avg_f1:.3f} & {avg_bert:.3f} & {avg_comet:.3f} \\\\\n"
latex_table += "\\bottomrule\n\\end{tabular}\n"
latex_table += "\\caption{{Language-wise performance of the Qwen-based system across key metrics. Best values are bolded.}}\n"
latex_table += "\\label{{tab:language_results}}\n\\end{table}\n"

with open("language_results_table.tex", "w", encoding="utf-8") as f:
    f.write(latex_table)

print("\nüìÑ LaTeX table saved as language_results_table.tex")
print("‚úÖ Plots saved:")
print(" - qwen_taskwise_performance_unified.png")
print(" - qwen_languagewise_performance_unified.png")
