\subsection{Multilingual Q\&A Generation}
For the Q\&A subtask, each question was answered based on the original dialogue context rather than using summaries alone.
The full doctor–patient conversation was provided to the model as input, ensuring access to both explicit and implicit medical details that might not appear in the summary.
The prompt template was structured as follows:
\begin{quote}\small
System: You are a helpful multilingual clinical assistant. Answer in the same language as the dialogue. \\
User: Dialogue: [Doctor–Patient conversation] \\
Question: [User question] \\
Answer in the same language as the question.
\end{quote}

By conditioning the model on the entire dialogue, we ensured contextually grounded answers reflecting both patient symptoms and doctor explanations.
Greedy decoding (\texttt{do\_sample=False}) was used to maintain factual and linguistic consistency.
This design enabled accurate cross-lingual Q\&A generation even for low-resource languages.
