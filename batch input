\documentclass[11pt]{article}
\usepackage[review]{acl}

\usepackage{times}
\usepackage{latexsym}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{microtype}
\usepackage{inconsolata}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{tabularx}
\usepackage{caption}
\usepackage{tikz}
\usepackage{float}
\renewcommand{\UrlFont}{\ttfamily\small}

% spacing tweaks
\setlength{\parskip}{4pt}
\setlength{\abovecaptionskip}{3pt}
\setlength{\belowcaptionskip}{3pt}

\title{Multilingual Clinical Dialogue Summarization and Information Extraction with Qwen-1.5B LoRA}

\author{
Anonymous Submission \\
NLP-AI4Health 2025 Shared Task
}

\begin{document}
\maketitle

\begin{abstract}
This paper describes our submission to the NLP-AI4Health 2025 Shared Task on multilingual clinical dialogue summarization and structured information extraction.
Our system is based on Qwen-1.5B Instruct fine-tuned with LoRA adapters for parameter-efficient adaptation.
The pipeline produces (i) concise English summaries, (ii) schema-aligned JSON outputs, and (iii) multilingual Q\&A responses.
The Qwen-based approach substantially improves summary fluency, factual completeness, and JSON field coverage while maintaining efficiency within constrained GPU resources.
\end{abstract}

\section{Introduction}
The 2025 Shared Task on multilingual clinical dialogue summarization challenges systems to process doctor–patient conversations across ten languages and output three modalities: summaries, structured records, and Q\&A responses.
We present a LoRA-adapted Qwen-1.5B pipeline optimized for factual summarization and schema-based information extraction, designed to handle multilingual inputs efficiently under limited hardware conditions.

\section{System Architecture and Approach}

\begin{figure*}[htbp!]
\centering
\includegraphics[width=\textwidth]{latex/Multilingual Doctor-Patient Dialogue.png}
\vspace{0em}
\caption{Overview of the multilingual summarization and extraction pipeline. The pipeline includes English summarization, structured information extraction, and multilingual Q\&A generation.}
\label{fig:struct}
\end{figure*}

Figure~\ref{fig:struct} shows the modular inference design of the pipeline. Each dialogue passes through sequential stages: English summarization, structured field extraction, and multilingual Q\&A generation.

\subsection{Model Configuration}
We used Qwen-1.5B Instruct quantized to 4-bit NF4 precision via \texttt{BitsAndBytes}.
LoRA adapters were trained with rank $r=8$, $\alpha=32$, dropout $0.05$, and target modules \texttt{q\_proj} and \texttt{v\_proj}.
Training used the AdamW optimizer ($2\times10^{-4}$ learning rate, cosine decay).
Gradient checkpointing and mixed precision allowed training within 60GB RAM and 32×V100 GPUs.

\paragraph{Training Details.}
Training was performed for a single epoch due to limited compute and strict task deadlines.
Despite only one pass, validation indicated rapid domain adaptation and stable convergence, while further epochs offered diminishing improvements relative to time cost.

\subsection{Inference Pipeline}
Each language’s dialogues were processed independently with checkpoint resumption support.
The inference proceeds through:
\begin{enumerate}
    \item \textbf{Summary Generation:} Produce an English summary ending with sentinel token \texttt{<<END>>}.
    \item \textbf{Structured Extraction:} Populate each JSON field by querying the model separately.
    \item \textbf{Multilingual Q\&A:} Generate answers in the dialogue’s original language.
\end{enumerate}
Greedy decoding (\texttt{do\_sample=False}) ensures stable, deterministic outputs across runs.

\subsection{Prompt Design for Inference}
The system employs role-based prompts for consistent and interpretable outputs across all subtasks.  
Distinct prompt templates were used for the three subtasks: summary generation, structured JSON extraction, and multilingual Q\&A.  
Each follows an explicit \textit{System–User} role format to improve controllability and output consistency.

\subsubsection*{Summary Prompt}
\textbf{System:}
\begin{quote}\footnotesize\ttfamily
You are a clinical summarization assistant. Write a fluent English summary focusing on diagnosis, symptoms, investigations, and management plan.  
End your summary with the token <<END>>.
\end{quote}

\textbf{User:}
\begin{quote}\footnotesize\ttfamily
Dialogue:\\
[doctor--patient conversation]\\
Write the summary and end with <<END>>.
\end{quote}

\subsubsection*{JSON Extraction Prompt}
\textbf{System:}
\begin{quote}\footnotesize\ttfamily
You are a concise clinical information extraction assistant.  
Answer in English only.  
If the information is not present, answer exactly ``N/A''.
\end{quote}

\textbf{User:}
\begin{quote}\footnotesize\ttfamily
Summary:\\
[summary]\\
Dialogue:\\
[conversation]\\
Question: [specific field]\\
Answer concisely.
\end{quote}

\subsubsection*{Q\&A Prompt}
\textbf{System:}
\begin{quote}\footnotesize\ttfamily
You are a multilingual clinical assistant.  
Answer in the same language as the user's question.
\end{quote}

\textbf{User:}
\begin{quote}\footnotesize\ttfamily
Question ([language]): [user query text]
\end{quote}

\subsection{Field-by-Field JSON Extraction}
Instead of prompting the model to generate the entire schema, each JSON field is treated as a \textit{question–answer} task.
For example:
\begin{quote}\small
Q: What is the patient's chief complaint? \\
A: Persistent throat discomfort and hoarseness for two months.
\end{quote}
This modular design improved JSON field coverage $\sim$3× compared to single-shot JSON prompting and allowed missing fields to be regenerated individually.

\begin{table}[htbp!]
\centering
\small
\setlength{\tabcolsep}{4pt}
\renewcommand{\arraystretch}{1.1}
\begin{tabular}{lp{0.3\textwidth}}
\toprule
\textbf{Field} & \textbf{Example Q-A Pair (≤12 words)} \\
\midrule
Chief Complaint & Q: What is the patient’s chief complaint? \newline
A: Persistent throat discomfort and hoarseness for two months. \\
Past Medical History & Q: Summarize past medical history. \newline
A: No major illnesses reported previously. \\
Management Plan & Q: Summarize management plan. \newline
A: Schedule biopsy and CT scan; smoking cessation counselling. \\
\bottomrule
\end{tabular}
\caption{Examples of field-level question–answer pairs used in structured extraction.}
\label{tab:jsonqa}
\end{table}

Table~\ref{tab:jsonqa} shows example Q–A pairs used to extract structured fields during inference.

\section{Dataset and Preprocessing}
We used the multilingual clinical dialogue dataset provided by the organizers, covering 10 languages: English, Hindi, Gujarati, Tamil, Telugu, Marathi, Kannada, Bangla, Assamese, and Dogri.
Dialogues were concatenated turn-wise and normalized for whitespace and encoding.
Native Indic scripts were retained, avoiding romanization to preserve token integrity for Qwen’s multilingual tokenizer.

\section{Experimental Setup and Results}

\begin{figure}[htbp!]
\centering
\includegraphics[width=\columnwidth]{latex/avg_per_task.png}
\vspace{0em}
\caption{Average task-wise scores (F1, BERT-F1, COMET) across the three subtasks.}
\label{fig:taskwise}
\end{figure}

Figure~\ref{fig:taskwise} summarizes average scores across subtasks.  
Summary generation achieved the highest semantic accuracy (BERT-F1 $\approx$ 0.83), QnA responses showed moderate factual alignment (F1 $\approx$ 0.46), and structured extraction (KNV) scored lower due to stricter field-level constraints.

\begin{table*}[htbp!]
\centering
\small
\setlength{\tabcolsep}{7pt}
\renewcommand{\arraystretch}{1.1}
\begin{tabular}{lcccc lcccc}
\toprule
\textbf{Language} & \textbf{QnA F1} & \textbf{ROUGE-L} & \textbf{BERT-F1} & \textbf{KNV F1} &
\textbf{Language} & \textbf{QnA F1} & \textbf{ROUGE-L} & \textbf{BERT-F1} & \textbf{KNV F1} \\
\midrule
Marathi  & 0.228 & 0.169 & 0.811 & 0.302 & Telugu   & 0.345 & 0.179 & 0.834 & 0.263 \\
Kannada  & 0.471 & 0.169 & 0.825 & 0.272 & Tamil    & 0.442 & 0.182 & 0.838 & 0.297 \\
Gujarati & 0.496 & 0.170 & 0.839 & 0.269 & Bangla   & 0.334 & 0.185 & 0.822 & 0.290 \\
English  & 0.674 & 0.191 & 0.835 & 0.335 & Hindi    & 0.618 & 0.176 & 0.836 & 0.344 \\
Assamese & 0.533 & 0.181 & 0.834 & 0.288 &          &       &       &       &      \\
\midrule
\textbf{Macro Avg.} & \textbf{0.460} & \textbf{0.178} & \textbf{0.830} & \textbf{0.296} & & & & & \\
\bottomrule
\end{tabular}
\caption{Official evaluation results across subtasks. QnA: macro F1. Summary\_Text: ROUGE-L and BERT-F1. Summary\_KNV: key–value F1.}
\label{tab:main-results}
\end{table*}

Table~\ref{tab:main-results} presents detailed performance across languages.  
English and Hindi performed best due to stronger data coverage, while Marathi and Assamese showed lower scores reflecting smaller training samples.

\section{Discussion}
Key challenges included limited GPU access, frequent checkpoint interruptions, and language imbalance for low-resource pairs (Dogri, Assamese).
Our design enabled selective skipping of completed languages and resumable training to maximize throughput.
Empirically, modular JSON generation increased field completion threefold and improved robustness across multilingual dialogues.

\section{Conclusion}
We presented a multilingual clinical dialogue summarization and structured extraction system based on Qwen-1.5B with LoRA adapters.
The approach balances factual precision, cross-lingual generalization, and computational efficiency.
Future work will explore retrieval-augmented factual grounding, factual consistency scoring, and scaling to larger Qwen variants.

\end{document}
