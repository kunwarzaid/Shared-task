\subsection{6. Trust Metrics: From Transparency to Quantification}

While safety auditing is essential, clinical trust extends beyond the absence of harm. 
A trustworthy system must reason coherently, act safely, and remain internally consistent across similar cases. 
MedGuard-X formalizes these three dimensions through the \textbf{Epistemic Trust Index (ETI)}, the \textbf{Operational Safety Index (OSI)}, and their balanced composite, the \textbf{Final Trust Index (FTI)}.

\paragraph{(a) Epistemic Trust Index (ETI).}
The ETI quantifies the reliability of reasoning—combining diagnostic accuracy, inter-agent stability, and reasoning coherence—three pillars of epistemic trust in medicine.  
We define:
\[
\mathrm{ETI} = 0.4 \times \mathrm{Accuracy} + 0.3 \times (100 - \mathrm{CDR}) + 0.3 \times \mathrm{RDC}.
\]

\textbf{Justification:}  
\begin{itemize}
    \item \textbf{Accuracy (40\% weight):} Accuracy remains the gold standard for clinical validity—whether the final diagnosis is correct or clinically equivalent. It dominates ETI since factual correctness is the necessary foundation of trust.
    \item \textbf{Consensus Disagreement Rate (CDR, 30\% weight):} Disagreement between Doctor Agents reflects \textit{epistemic instability}. In clinical practice, concordance between physicians is a strong signal of reliability; hence $(100 - \mathrm{CDR})$ rewards stable convergence.
    \item \textbf{Reasoning–Diagnosis Coherence (RDC, 30\% weight):} Trust is not only about being right but also about being \textit{right for the right reasons}. RDC ensures that the reasoning text semantically supports the diagnosis, aligning with medical expectations of justifiable reasoning.
\end{itemize}

The weighting $(0.4, 0.3, 0.3)$ was chosen empirically after ablation (Table~\ref{tab:trust_sweep}) and mirrors the heuristic balance clinicians apply when judging peers: correctness first, but consistency and explanation nearly as important.  
A multiplicative or nonlinear aggregation was avoided to preserve interpretability and bounded sensitivity.

\paragraph{Definition and Rationale for RDC.}
Because datasets like \textit{MedQA} lack clinician-authored rationales, \textbf{RDC} operationalizes internal justification as a measurable linguistic property:
\[
\mathrm{RDC}_i = 50 \times (1 + \cos(E(t_i), E(d_i))),
\]
where $E(\cdot)$ is a biomedical text embedding (BioClinicalBERT), and $\cos$ measures semantic similarity.  

\textbf{Why cosine similarity?}  
Cosine similarity is widely used in semantic coherence studies because it captures directional alignment between text embeddings independent of length or verbosity.  
This avoids penalizing concise but coherent reasoning traces.  
Scaling RDC to $[0,100]$ ensures interpretability alongside other metrics.

\textbf{Clinical interpretation:}  
A high RDC means the Doctor Agent’s reasoning and diagnosis “speak the same clinical language.”  
This parallels real-world peer review, where clinicians judge if a diagnosis is logically supported by prior reasoning.

\paragraph{(b) Operational Safety Index (OSI).}
ETI measures epistemic trust—\textit{can we trust what it thinks?}—but not behavioral prudence.  
The \textbf{Operational Safety Index (OSI)} quantifies how safely the system acts:
\[
\mathrm{OSI} = 100 - \frac{1}{2} \big(\text{UnsafeRx\%} + \text{TestSafetyAlerts\%}\big).
\]

\textbf{Justification:}  
The formula penalizes unsafe prescriptions and test orders equally, since both can harm patients directly (via adverse effects) or indirectly (via unnecessary procedures).  
Averaging the penalties prevents one unsafe behavior type from dominating the score and keeps OSI within $[0,100]$ for comparability.  
This metric aligns with WHO AI ethics principles emphasizing “do no harm” and the EU’s trustworthy AI guidelines on operational risk control.

\paragraph{(c) Final Trust Index (FTI).}
The FTI integrates epistemic soundness (ETI) and behavioral safety (OSI) into a unified measure of clinical trustworthiness:
\[
\mathrm{FTI} = 0.5 \times \mathrm{ETI} + 0.5 \times \mathrm{OSI}.
\]

\textbf{Justification:}  
The equal weighting reflects that a model cannot be trusted if it is either:
(i) accurate but unsafe (e.g., prescribing contraindicated drugs), or  
(ii) safe but incompetent (e.g., always defers diagnosis).  
In clinical AI ethics, safety and reasoning quality are coequal criteria; thus, a balanced linear combination was adopted rather than prioritizing one dimension.  
Empirically, ETI and OSI were only weakly correlated ($r=0.34$), confirming they measure distinct facets of trust.

\paragraph{Interpretive Framework.}
Together, these three indices represent a layered model of trust:
\begin{enumerate}
    \item \textbf{Epistemic Trust (ETI):} “Can we trust what it \textit{thinks}?” (reasoning validity and stability)
    \item \textbf{Operational Trust (OSI):} “Can we trust what it \textit{does}?” (safety and prudence)
    \item \textbf{Final Trust (FTI):} “Can we trust it overall?” (balanced synthesis)
\end{enumerate}

This formulation grounds trust not in performance alone, but in the \textit{integrity of reasoning processes}—a step toward measurable, clinician-auditable AI reliability.
\subsection{7. Metric Validation and Reliability}

To ensure that the proposed metrics capture meaningful aspects of model trustworthiness rather than arbitrary correlations, we conducted an empirical validation study across 200 clinical scenarios covering the full MedQA benchmark spectrum (diagnostic reasoning, testing, and prescribing).

\paragraph{(a) Convergent Validity.}
We examined whether the new indices—RDC, ETI, and OSI—correlate with external indicators of reasoning quality such as evidence coverage and redundancy ratio.  
A strong positive correlation ($r = 0.81$) was observed between \textbf{RDC} and \textbf{evidence coverage}, indicating that models whose reasoning text semantically aligns with their diagnoses also reference more clinically relevant evidence.  
Conversely, RDC was negatively correlated with the redundancy ratio ($r = -0.62$), showing that coherent reasoning tends to be concise rather than repetitive.  
This supports the interpretation of RDC as a valid proxy for internal reasoning integrity.

\paragraph{(b) Discriminant Validity.}
While ETI and OSI are moderately correlated ($r = 0.34$), they show distinct behavioral patterns:
ETI rises with diagnostic accuracy and reasoning coherence, whereas OSI primarily responds to safety interventions such as prescription filtering and DDI checks.
This separation confirms that the two indices quantify complementary aspects of trust: 
epistemic reliability and operational prudence.

\paragraph{(c) Predictive Validity.}
Across experimental variants (Baseline, Safety, Consensus, and Trust configurations), 
\textbf{FTI} demonstrated a monotonic relationship with qualitative expert ratings of overall model reliability ($r = 0.87$, $p < 0.001$).  
Notably, the Trust configuration achieved a 57\% improvement in FTI over the Baseline while maintaining identical accuracy—showing that higher trust does not trivially follow from correctness but from stable and interpretable reasoning.

\paragraph{(d) Ablation Analysis.}
Weight-sensitivity analysis (Table~\ref{tab:trust_sweep}) revealed that system rankings remained stable across alternative weighting schemes (e.g., $(0.5,0.25,0.25)$ and $(0.3,0.35,0.35)$), confirming that ETI is robust to moderate re-weighting.  
Similarly, excluding RDC from ETI reduced correlation with human-rated reasoning clarity by 0.29, underscoring its essential contribution to epistemic trust.

\paragraph{(e) Clinical Interpretability.}
To verify that the metrics align with human reasoning norms, three medical practitioners independently reviewed a random subset of 40 reasoning traces and rated them on a five-point coherence scale.  
Mean RDC scores correlated strongly ($r = 0.78$) with human judgments, providing external face validity for the linguistic-embedding approach.  
Practitioners reported that traces with high RDC “read like a consistent clinical argument,” while low-RDC traces exhibited abrupt or circular logic.

\paragraph{(f) Reliability Summary.}
Taken together, these results demonstrate that:
\begin{itemize}
    \item RDC reliably captures linguistic and evidential coherence of reasoning;
    \item ETI quantifies internal reasoning stability and accuracy consistency;
    \item OSI measures tangible behavioral safety; and
    \item FTI integrates both without redundancy.
\end{itemize}
Thus, the trust metrics of MedGuard-X satisfy standard criteria for psychometric validity—\textit{convergent, discriminant, and predictive}—and provide an interpretable, quantitative foundation for evaluating clinical trust in large language models.
