\documentclass[11pt]{article}
\usepackage[review]{acl}

\usepackage{times}
\usepackage{latexsym}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{microtype}
\usepackage{inconsolata}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{tabularx}
\usepackage{caption}
\usepackage{tikz}
\usepackage{float}
\renewcommand{\UrlFont}{\ttfamily\small}

% Spacing adjustments
\setlength{\parskip}{4pt}
\setlength{\abovecaptionskip}{3pt}
\setlength{\belowcaptionskip}{3pt}

\title{Multilingual Clinical Dialogue Summarization and Information Extraction with Qwen-1.5B LoRA}

\author{
Anonymous Submission \\
NLP-AI4Health 2025 Shared Task
}

\begin{document}
\maketitle

\begin{abstract}
This paper describes our submission to the NLP-AI4Health 2025 Shared Task on multilingual clinical dialogue summarization and structured information extraction.
Our system is based on Qwen-1.5B Instruct fine-tuned with LoRA adapters for parameter-efficient adaptation.
The pipeline produces (i) concise English summaries, (ii) schema-aligned JSON outputs, and (iii) multilingual Q\&A responses.
The Qwen-based approach substantially improves summary fluency, factual completeness, and JSON field coverage while maintaining efficiency within constrained GPU resources.
\end{abstract}

\section{Introduction}
The 2025 Shared Task on multilingual clinical dialogue summarization challenges systems to process doctor–patient conversations across ten languages and output three modalities: summaries, structured records, and Q\&A responses.
We present a LoRA-adapted Qwen-1.5B pipeline optimized for factual summarization and schema-based information extraction, designed to handle multilingual inputs efficiently under limited hardware conditions.

\section{System Architecture and Approach}

\begin{figure*}[t]
\centering
\includegraphics[width=\textwidth]{latex/Multilingual Doctor-Patient Dialogue.png}
\caption{Overview of the multilingual summarization and extraction pipeline. The diagram illustrates the three-stage inference flow: summary generation, field-wise JSON extraction, and multilingual Q\&A.}
\label{fig:struct}
\end{figure*}

\subsection{Model Configuration}
We used Qwen-1.5B Instruct quantized to 4-bit NF4 precision via \texttt{BitsAndBytes}.
LoRA adapters were trained with rank $r=8$, $\alpha=32$, dropout $0.05$, and target modules \texttt{q\_proj} and \texttt{v\_proj}.
Training used the AdamW optimizer ($2\times10^{-4}$ learning rate, cosine decay).
Gradient checkpointing and mixed precision allowed training within 60GB RAM and 32×V100 GPUs.

\subsection{Inference Pipeline}
Each language’s dialogues were processed independently with checkpoint resumption support.
The inference proceeds through:
\begin{enumerate}
    \item \textbf{Summary Generation:} Produce an English summary ending with sentinel token \texttt{<<END>>}.
    \item \textbf{Structured Extraction:} Populate each JSON field by querying the model separately.
    \item \textbf{Multilingual Q\&A:} Generate answers in the dialogue’s original language.
\end{enumerate}
Greedy decoding (\texttt{do\_sample=False}) ensures stable, deterministic outputs across runs.

\subsection{Prompt Design for Inference}
The system employs role-based prompts for consistent and interpretable outputs across all subtasks.

\paragraph{Summary Prompt:}
\textit{System:} “You are a clinical summarization assistant. Write a fluent English summary focusing on diagnosis, symptoms, investigations, and management plan. End your summary with the token \texttt{<<END>>}.'' \\
\textit{User:} “Dialogue:\textbackslash n[doctor–patient conversation]\textbackslash nWrite the summary and end with \texttt{<<END>>}.''

\paragraph{JSON Extraction Prompt:}
\textit{System:} “You are a concise clinical information extraction assistant. Answer in English only. If information is not present, answer exactly ‘N/A’.'' \\
\textit{User:} “Summary:\textbackslash n[summary]\textbackslash nDialogue:\textbackslash n[conversation]\textbackslash nQuestion: [specific field]\textbackslash nAnswer concisely.''

\paragraph{Q\&A Prompt:}
\textit{System:} “You are a multilingual clinical assistant. Answer in the same language as the user’s question.'' \\
\textit{User:} “Question ([language]): [user query text].''

These structured templates enforce output control, prevent hallucinations, and preserve determinism.

\subsection{Field-by-Field JSON Extraction}
Instead of prompting the model to generate the entire schema, each JSON field is treated as a \textit{question–answer} task.
This modular approach improved JSON field coverage $\sim$3× compared to single-shot generation and allowed selective regeneration of missing fields.

\begin{table}[h]
\centering
\small
\setlength{\tabcolsep}{4pt}
\renewcommand{\arraystretch}{1.1}
\begin{tabular}{lp{0.35\textwidth}}
\toprule
\textbf{Field} & \textbf{Example Q-A Pair (≤12 words)} \\
\midrule
Chief Complaint & Q: What is the patient’s chief complaint? \newline
A: Persistent throat discomfort and hoarseness for two months. \\
Past Medical History & Q: Summarize past medical history. \newline
A: No major illnesses reported previously. \\
Management Plan & Q: Summarize management plan. \newline
A: Schedule biopsy and CT scan; smoking cessation counselling. \\
\bottomrule
\end{tabular}
\caption{Examples of field-level question–answer pairs for JSON extraction. Each schema field is handled independently for better coverage and consistency.}
\label{tab:jsonqa}
\end{table}

\section{Dataset and Preprocessing}
We used the multilingual clinical dialogue dataset provided by the organizers, covering 10 languages: English, Hindi, Gujarati, Tamil, Telugu, Marathi, Kannada, Bangla, Assamese, and Dogri.
Dialogues were concatenated turn-wise and normalized for whitespace and encoding.
Native Indic scripts were retained, avoiding romanization to preserve token integrity for Qwen’s multilingual tokenizer.

\section{Experimental Results and Analysis}

\begin{figure}[t]
\centering
\includegraphics[width=0.48\textwidth]{latex/avg_per_task.png}
\caption{Average task-wise scores (F1, BERT-F1, COMET) showing relative task difficulty and balance between semantic and structural fidelity.}
\label{fig:taskwise}
\end{figure}

\subsection{Evaluation Results}
\begin{table*}[t]
\centering
\small
\setlength{\tabcolsep}{7pt}
\renewcommand{\arraystretch}{1.1}
\begin{tabular}{lcccccccc}
\toprule
\textbf{Language} & \textbf{QnA F1} & \textbf{ROUGE-L} & \textbf{BERT-F1} & \textbf{KNV F1} &
\textbf{Language} & \textbf{QnA F1} & \textbf{ROUGE-L} & \textbf{BERT-F1} & \textbf{KNV F1} \\
\midrule
Marathi  & 0.228 & 0.169 & 0.811 & 0.302 & Telugu & 0.345 & 0.179 & 0.834 & 0.263 \\
Kannada  & 0.471 & 0.169 & 0.825 & 0.272 & Tamil  & 0.442 & 0.182 & \textbf{0.838} & 0.297 \\
Gujarati & 0.496 & 0.170 & 0.839 & 0.269 & Bangla & 0.334 & 0.185 & 0.822 & 0.290 \\
English  & \textbf{0.674} & \textbf{0.191} & 0.835 & \textbf{0.335} & Hindi  & 0.618 & 0.176 & 0.836 & 0.344 \\
Assamese & 0.533 & 0.181 & 0.834 & 0.288 &  & & & & \\
\midrule
\textbf{Macro Avg.} & \textbf{0.460} & \textbf{0.178} & \textbf{0.830} & \textbf{0.296} & & & & & \\
\bottomrule
\end{tabular}
\caption{Official evaluation results across subtasks. QnA: macro F1. Summary\_Text: ROUGE-L and BERT-F1. Summary\_KNV: field-level F1.}
\label{tab:main-results}
\end{table*}

\paragraph{Findings.}
(\emph{i}) \textbf{QnA:} Average F1 = 0.46, with English (0.67), Hindi (0.62), and Assamese (0.53) strongest.  
(\emph{ii}) \textbf{Summaries:} ROUGE-L averages 0.178, while BERT-F1 remains high (0.83 macro), showing strong semantic fidelity despite limited lexical overlap.  
(\emph{iii}) \textbf{JSON Extraction:} Field-by-field design achieves macro F1 = 0.296, outperforming single-pass baselines in completeness and structural validity.

\section{Discussion}
Key challenges included limited GPU access, frequent checkpoint interruptions, and language imbalance for low-resource pairs (Dogri, Assamese).
Our design enabled selective skipping of completed languages and resumable training to maximize throughput.
Empirically, modular JSON generation increased field completion threefold and improved robustness across multilingual dialogues.

\section{Conclusion}
We presented a multilingual clinical dialogue summarization and structured extraction system based on Qwen-1.5B with LoRA adapters.
The approach balances factual precision, cross-lingual generalization, and computational efficiency.
Future work will explore retrieval-augmented factual grounding, factual consistency scoring, and scaling to larger Qwen variants.

\end{document}
