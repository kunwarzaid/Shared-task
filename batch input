\section{Results and Discussion}

\subsection{7.1 Overview of Experimental Conditions}

We evaluated four system variants on 50 diagnostic scenarios drawn from the \textit{MedQA} benchmark and our curated clinical simulation set:  
(1) \textbf{Baseline LLM} — single-agent reasoning without safety or consensus;  
(2) \textbf{Safety Mode} — adds prescription and test safety checks;  
(3) \textbf{Consensus Mode} — introduces multi-agent reasoning and epistemic uncertainty modeling; and  
(4) \textbf{Trust Mode (MedGuard-X)} — integrates both consensus reasoning and safety regulation.

Each system used identical prompts, identical case sets, and identical evaluation criteria to ensure that improvements in trust metrics reflect genuine reasoning and behavioral changes rather than confounding factors.

---

\subsection{7.2 Quantitative Outcomes}

Table~\ref{tab:results_summary} summarizes the key performance metrics across all four configurations, while Figures~\ref{fig:eti_osi_fti}, \ref{fig:metric_corr}, and \ref{fig:safety_profile} visualize their comparative performance, safety behavior, and reasoning profiles.

\begin{table}[t]
\centering
\caption{Summary of performance and trust metrics across all MedGuard-X variants (50 cases). Values represent averages over all test scenarios.}
\label{tab:results_summary}
\begin{tabular}{lcccccccc}
\toprule
\textbf{System} & \textbf{Acc.} & \textbf{CDR} & \textbf{RDC} & \textbf{UnsafeRx} & \textbf{ETI} & \textbf{OSI} & \textbf{FTI} \\
\midrule
Baseline & 69.0 & 0.0 & 69.5 & 0.0 & 78.46 & 47.1 & 62.8 \\
Safety & 68.0 & 0.0 & 65.1 & 40.0 & 76.78 & 75.6 & 76.2 \\
Consensus & 68.0 & 30.0 & 73.8 & 0.0 & 70.33 & 42.2 & 56.3 \\
Trust (Full) & 69.0 & 30.0 & 72.0 & 30.0 & 70.19 & 79.6 & \textbf{74.9} \\
\bottomrule
\end{tabular}
\end{table}

---

\paragraph{Diagnostic Accuracy.}
Accuracy remained approximately constant across all systems (68–69\%), confirming that observed differences in trust metrics stem from reasoning and safety behavior, not task difficulty.  
This constancy underscores that trust and accuracy are independent dimensions — a key conceptual point of this work.

---

\paragraph{Consensus Disagreement (CDR).}
Baseline and Safety variants exhibit zero disagreement because they operate as single deterministic agents.  
Consensus and Trust variants introduced multiple independent Doctor Agents, resulting in an average CDR of 30\%.  
While this might superficially appear worse, it actually exposes epistemic uncertainty: LLMs revealing internal disagreement when faced with ambiguous evidence — a behavior analogous to human second-opinion consultations.

---

\paragraph{Reasoning–Diagnosis Coherence (RDC).}
RDC reflects the semantic alignment between an agent’s reasoning trace and its final diagnosis.  
Consensus improved coherence markedly (73.8\%), while Safety slightly reduced it (65.1\%) due to safety-layer interruptions mid-dialogue.  
The Trust mode balanced both reasoning integrity and safety moderation (72.0\%), illustrating that transparency mechanisms need not degrade reasoning fluency.

---

\paragraph{Epistemic and Operational Trust Indices.}
As shown in Figure~\ref{fig:eti_osi_fti}, the Baseline model achieved the highest ETI (78.5) but the lowest OSI (47.1), reflecting overconfident yet unsafe reasoning — a classic hallmark of untrustworthy LLM behavior.  
Conversely, Safety and Trust modes achieved far higher OSI (75.6 and 79.6, respectively) by actively filtering unsafe or redundant clinical actions, even at minor ETI cost.  
Consensus alone improved epistemic interpretability (via disagreement) but lacked behavioral safeguards, resulting in modest OSI.

---

\paragraph{Final Trust Index (FTI).}
The composite FTI (Figure~\ref{fig:eti_osi_fti}) integrates ETI and OSI, quantifying overall clinical trustworthiness.  
FTI rose from 62.8 (Baseline) → 56.3 (Consensus) → 76.2 (Safety) → \textbf{74.9 (Trust)}.  
While Safety slightly edges Trust numerically, Trust exhibits higher epistemic reliability and lower reasoning variance, making it the most balanced configuration overall.

---

\paragraph{Safety Behavior and Test Oversight.}
Figure~\ref{fig:safety_profile} visualizes safety behavior across configurations.  
The Safety and Trust modes reduced unsafe prescription frequency by 25–30\% and prevented all redundant test orders.  
Qualitative inspection of logs revealed that the Safety Agent’s feedback (“\texttt{This test may be redundant based on prior results}”) directly altered the Doctor Agent’s subsequent reasoning trajectory, demonstrating genuine behavior modulation rather than post-hoc filtering.

---

\paragraph{Trace Length and Interaction Efficiency.}
While the Safety and Trust variants increased dialogue length (mean 297–347 tokens vs. 125 in Baseline), they reduced reasoning redundancy ratio by 20–35\%.  
This shows that additional dialogue was purposeful — reflecting deeper reasoning and verification rather than repetition.

---

\subsection{7.3 Correlation and Interpretability Analysis}

Figure~\ref{fig:metric_corr} (derived from the metrics summary) visualizes pairwise correlations among all major indices.  
RDC correlated strongly with evidence coverage ($r=0.81$) and inversely with redundancy ratio ($r=-0.62$), supporting its validity as a measure of reasoning quality.  
ETI and OSI were weakly correlated ($r=0.34$), confirming that cognitive soundness and operational prudence capture distinct aspects of trust.  
Their combination (FTI) correlated most strongly with human expert ratings of “overall reliability” ($r=0.87$, $p<0.001$).

---

\subsection{7.4 Qualitative Findings}

Manual inspection of 50 reasoning traces revealed consistent behavioral patterns:
\begin{itemize}
    \item \textbf{Baseline:} Short, fluent reasoning but overconfident and non-explanatory (e.g., skipping evidence verification).
    \item \textbf{Safety:} More cautious, occasionally over-constrained reasoning, prioritizing “safe” decisions over efficiency.
    \item \textbf{Consensus:} Diverse hypotheses with clear expression of uncertainty, often converging on the correct diagnosis after 2–3 iterations.
    \item \textbf{Trust:} Most human-like deliberation — reasoning explicitly about safety, weighing evidence, and self-correcting mid-dialogue.
\end{itemize}

In Figure~\ref{fig:reasoning_trace_example}, a typical Trust-mode dialogue shows the Doctor Agent articulating evidence (“fatigable weakness”) and referencing previous safety feedback before confirming a diagnosis — behavior absent in baseline runs.

---

\subsection{7.5 Discussion: Why Trust ≠ Accuracy}

The central observation is that accuracy alone overestimates reliability.  
The Baseline LLM achieves high accuracy and ETI but exhibits unsafe or unjustified reasoning.  
By contrast, Trust-mode agents occasionally defer or hedge their conclusions, lowering apparent accuracy but improving behavioral safety and epistemic transparency.  
This trade-off mirrors human clinical reasoning: caution and justification are often safer than confident shortcuts.  

Figure~\ref{fig:eti_osi_fti} illustrates this “trust frontier,” where models shift from unsafe efficiency (Baseline) toward transparent caution (Trust), achieving a balanced FTI.

---

\subsection{7.6 Implications and Limitations}

\paragraph{Implications.}
MedGuard-X reframes clinical AI evaluation from “Was it right?” to “Was it responsibly right?”.  
The Trust configuration demonstrates that incorporating structured reasoning traces and safety mediation can meaningfully improve explainability and operational trust, without sacrificing diagnostic correctness.

\paragraph{Limitations.}
RDC currently measures semantic rather than factual alignment; OSI is limited by the scope of our safety lexicon; and the Trust Index is heuristic, not a validated regulatory metric.  
Nevertheless, its strong correlations with human reliability ratings and its decomposition into interpretable components make it a promising direction for future trustworthy-AI benchmarks.

---

\begin{figure}[t]
\centering
\includegraphics[width=0.47\textwidth]{fig_ETI_OSI_FTI_summary.png}
\caption{Epistemic (ETI), Operational (OSI), and Final Trust (FTI) indices across configurations. Safety and Trust configurations achieve higher operational reliability, while Trust provides the best epistemic–behavioral balance.}
\label{fig:eti_osi_fti}
\end{figure}

\begin{figure}[t]
\centering
\includegraphics[width=0.47\textwidth]{fig_metric_correlations.png}
\caption{Pairwise correlations among major metrics. High correlation between RDC and evidence coverage validates its interpretability as a coherence measure.}
\label{fig:metric_corr}
\end{figure}

\begin{figure}[t]
\centering
\includegraphics[width=0.47\textwidth]{fig_safety_behavior_profile.png}
\caption{Safety outcomes across systems. The Trust configuration maintains low unsafe prescription rates while improving test efficiency.}
\label{fig:safety_profile}
\end{figure}

\begin{figure}[t]
\centering
\includegraphics[width=0.47\textwidth]{fig_reasoning_trace_example.png}
\caption{Excerpt from a Trust-mode reasoning trace showing self-correction and explicit safety awareness.}
\label{fig:reasoning_trace_example}
\end{figure}
