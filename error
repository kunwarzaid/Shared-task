from transformers import pipeline

# Load once
summarizer = pipeline("text-generation", model="google/gemma-2b-it", device_map="auto")

def generate_summary(dialogue, mode="text"):
    if mode == "text":
        prompt = f"""
Summarize the following doctorâ€“patient dialogue in English.
Organize into sections like Context, Presentation, Assessment, Plan, and Follow-up.

Dialogue:
{dialogue}

### Response:
"""
    elif mode == "json":
        prompt = f"""
Extract structured clinical information from the following dialogue.
Return valid JSON with keys:
chief_complaint, symptom_description, social_history,
assessment_primary_diagnosis, management_plan, follow_up_plan,
patient_concerns_preferences_consent.

Dialogue:
{dialogue}

### JSON Output:
"""
    else:
        raise ValueError("mode must be 'text' or 'json'")

    result = summarizer(prompt, max_new_tokens=600, do_sample=False)[0]["generated_text"]
    # Strip prompt text cleanly
    return result.split("### Response:")[-1].split("### JSON Output:")[-1].strip()
