# Path to the train_split used for few-shot examples
TRAIN_SPLIT_DIR = "/workspace/data/KZ_2117574/SharedTask_NLPAI4Health_Train&dev_set/train_split"

# number of few-shot examples per target language (k-shot)
FEW_SHOT_K = 3

# seed for deterministic sampling of few-shot examples
FEW_SHOT_SEED = 42

import random

def collect_few_shot_examples(train_split_root: str, lang: str, k: int, seed: int = 42):
    """
    Find up to k (dialogue_text, summary_text) pairs for `lang` from train_split.
    Deterministic shuffle using `seed`.
    Returns list of tuples: [(dialogue_str, summary_str), ...]
    """
    lang_dir = Path(train_split_root) / lang
    dlg_dir = lang_dir / "Dialogues"
    summ_dir = lang_dir / "Summary_Text"
    examples = []

    if not dlg_dir.exists() or not summ_dir.exists():
        return examples

    json_files = sorted(dlg_dir.glob("*.jsonl"))
    rng = random.Random(seed)

    # collect pairs where both files exist and non-empty
    pairs = []
    for f in json_files:
        summ_file = summ_dir / f"{f.stem}_summary.txt"
        if not summ_file.exists():
            continue
        try:
            # read dialogue
            rows = safe_read_jsonl(f)
            dialogue = " ".join(
                r.get("dialogue", "") if isinstance(r, dict) else str(r)
                for r in rows
            ).strip()
            if not dialogue:
                continue
            # read summary (strip ending tokens if any)
            summary = summ_file.read_text(encoding="utf-8", errors="replace").strip()
            if not summary:
                continue
            pairs.append((f, dialogue, summary))
        except Exception:
            continue

    rng.shuffle(pairs)
    for idx, (_, dialogue, summary) in enumerate(pairs[:k]):
        examples.append((dialogue, summary))
    return examples

# -------------------------
# Build few-shot prefix (per language) and final user prompt
# -------------------------
few_examples = collect_few_shot_examples(TRAIN_SPLIT_DIR, lang, FEW_SHOT_K, seed=FEW_SHOT_SEED)

# Build few-shot string: Example 1 / Example 2 / ...
few_shot_str = ""
if few_examples:
    # Use short formatting that is easy for the model to parse
    parts = []
    for i, (ex_dialogue, ex_summary) in enumerate(few_examples, start=1):
        # clip example dialogues to avoid blowing context with huge examples
        ex_dialogue_clip = clip_tokens(tokenizer, ex_dialogue, max_input_tokens // 4)
        # ensure summary ends without <<END>> token (we will mark real target)
        ex_summary_clean = ex_summary.replace("<<END>>", "").strip()
        parts.append(
            f"Example {i}:\nDialogue:\n{ex_dialogue_clip}\n\n"
            f"English Summary:\n{ex_summary_clean}\n---"
        )
    few_shot_str = "\n\n".join(parts)
    # final instruction intro for few-shot
    few_shot_str = (
        "Below are some examples of dialogues and their corresponding English summaries.\n\n"
        f"{few_shot_str}\n\n"
        "Now follow the same format for the next dialogue.\n\n"
    )
else:
    # If not enough few-shot examples, remain zero-shot
    few_shot_str = ""

# Now build the user prompt with few-shot prefix and the target dialogue
user_prompt = (
    f"{few_shot_str}"
    f"Dialogue:\n{dialogue_clip}\n\n"
    f"Write a detailed but concise English clinical summary and end with <<END>>."
)

# Build messages and generate as before
messages = build_messages(SYSTEM_SUMMARY, user_prompt)
summary_raw = chat_generate(model, tokenizer, messages, MAX_NEW_TOKENS_SUMMARY)

