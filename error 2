�⚠️ Skipped malformed QnA file scenario_43_bcb6ac84b7f043228d6b5be2372f34b7_IDX_02_3_questions.json: 'utf-8' codec can't decode byte 0xe0 in position 12287: unexpected end of data
✅ Loaded 223297 examples from /workspace/data/KZ_2117574/SharedTask_NLPAI4Health_Train&dev_set/train
✅ Loaded 13262 examples from /workspace/data/KZ_2117574/SharedTask_NLPAI4Health_Train&dev_set/dev
✅ Loaded 223297 train and 13262 dev examples

�    tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL)
  File "/usr/local/lib/python3.10/dist-packages/transformers/models/auto/tokenization_auto.py", line 862, in from_pretrained

�    return tokenizer_class.from_pretrained(pretrained_model_name_or_path, *inputs, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py", line 2089, in from_pretrained

�    return cls._from_pretrained(
  File "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py", line 2311, in _from_pretrained

�    tokenizer = cls(*init_inputs, **init_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/transformers/models/gemma/tokenization_gemma_fast.py", line 103, in __init__

�    super().__init__(
  File "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_fast.py", line 111, in __init__

�    fast_tokenizer = TokenizerFast.from_file(fast_tokenizer_file)
Exception: data did not match any variant of untagged enum ModelWrapper at line 2379610 column 3
