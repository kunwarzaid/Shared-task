 Starting fine-tuning (with resumable checkpoints)...
ðŸ”„ Resuming from /workspace/data/KZ_2117574/gemma1b_qlora_multilingual_finetune_fast/checkpoint-7000

ï¿½Traceback (most recent call last):
  File "/workspace/table-to-text-flan-t5/finetune_sharedtask_fast.py", line 314, in <module>

ï¿½    trainer.train(resume_from_checkpoint=latest_ckpt)
  File "/usr/local/lib/python3.10/dist-packages/transformers/trainer.py", line 2325, in train

ï¿½    return inner_training_loop(
  File "/usr/local/lib/python3.10/dist-packages/transformers/trainer.py", line 2510, in _inner_training_loop

ï¿½    self._load_optimizer_and_scheduler(resume_from_checkpoint)
  File "/usr/local/lib/python3.10/dist-packages/transformers/trainer.py", line 3589, in _load_optimizer_and_scheduler

ï¿½    check_torch_load_is_safe()
  File "/usr/local/lib/python3.10/dist-packages/transformers/utils/import_utils.py", line 1647, in check_torch_load_is_safe

k    raise ValueError(
ValueError: Due to a serious vulnerability issue in `torch.load`, even with `weights_only=True`, we now require users to upgrade torch to at least v2.6 in order to use the function. This version restriction does not apply when loading files with safetensors.
See the vulnerability report here https://nvd.nist.gov/vuln/detail/CVE-2025-32434
