�trainable params: 1,089,536 || all params: 1,544,803,840 || trainable%: 0.07052908413277896
[Resuming from /workspace/data/KZ_2117574/qwen15b_lora_multilingual/checkpoint-11000]

$ Trainer resuming at global step: 0

lTraceback (most recent call last):
  File "/workspace/table-to-text-flan-t5/qwen.py", line 252, in <module>

P    main()
  File "/workspace/table-to-text-flan-t5/qwen.py", line 241, in main

�    trainer.train(resume_from_checkpoint=ckpt)
  File "/usr/local/lib/python3.10/dist-packages/transformers/trainer.py", line 2325, in train

�    return inner_training_loop(
  File "/usr/local/lib/python3.10/dist-packages/transformers/trainer.py", line 2510, in _inner_training_loop

�    self._load_optimizer_and_scheduler(resume_from_checkpoint)
  File "/usr/local/lib/python3.10/dist-packages/transformers/trainer.py", line 3589, in _load_optimizer_and_scheduler

�    check_torch_load_is_safe()
  File "/usr/local/lib/python3.10/dist-packages/transformers/utils/import_utils.py", line 1647, in check_torch_load_is_safe

k    raise ValueError(
ValueError: Due to a serious vulnerability issue in `torch.load`, even with `weights_only=True`, we now require users to upgrade torch to at least v2.6 in order to use the function. This version restriction does not apply when loading files with safetensors.
See the vulnerability report here https://nvd.nist.gov/vuln/detail/CVE-2025-32434
