1.	CN117932042A
BIBLIOGRAPHIC INFORMATION
Title	Evaluation method and device of large language model as doctor agency
Assignee 	Alipay Hangzhou Information Technology Co Ltd
Priority date 	2024-03-21
Abstract
The embodiment of the specification provides a method and a device for evaluating a large language model serving as a doctor agency, wherein the method comprises the following steps: acquiring an initialized patient query statement of a patient agent from pre-constructed standardized patient information; inputting the initialized patient query sentence into the large language model to obtain a question back to the doctor agent; extracting key information characterizing item names in clinical medicine from the question-back question; retrieving corresponding value information from the standardized patient information according to the key information; when the value information is retrieved, the value information is used as an answer of a patient agent to the question back, and the large language model is input again so as to realize multiple rounds of dialogue; and determining index scores of the multiple rounds of dialogue corresponding to the evaluation indexes, wherein the index scores are used for measuring the capability of the large language model in clinical diagnosis and treatment. Accurate automatic evaluation can be realized.
Relevant Text
1. A method for evaluating a large language model as a doctor agent, the method comprising: Obtaining an initialization patient inquiry statement of a patient agent from pre-built standardized patient information; Inputting the initialized patient query sentence into the large language model to obtain a counter-question from the doctor agent; Extracting key information representing the name of an item in clinical medicine from the rhetorical question; According to the key information, retrieving corresponding value information from the standardized patient information; When the value information is retrieved, the value information is used as an answer of the patient agent to the rhetorical question and input into the large language model again to achieve a multi-round dialogue; Determine the index scores of the multiple rounds of dialogue corresponding to each evaluation index, and the index scores are used to measure the ability of the large language model in clinical diagnosis and treatment. 
2. The method according to claim 1, wherein extracting key information representing the name of an item in clinical medicine from the rhetorical question comprises: The rhetorical question is input into an extraction model as a patient agent to obtain the key information; wherein the extraction model is fine-tuned based on a training sample consisting of the rhetorical question and the key information. 
3. The method of claim 2, wherein the training samples are obtained by inputting key information contained in the standardized patient information into a generation model. 
4. The method of claim 1, wherein the method further comprises: When the value information is not retrieved, the multi-round dialogue is ended. 
5. The method of claim 1, wherein the key information and the corresponding value information include at least one of the following: Symptom name and corresponding symptom description; Inspection items and corresponding reports; Check the project and the corresponding report. 6. The method according to claim 1, wherein the evaluation index comprises: The first category of indicators used to examine the ability of physician agents to obtain objective evidence from patient agents; The first type of indicators include at least one of the information content of the rhetorical question and the logic of the rhetorical question; The amount of inverse question information determines the corresponding index score by whether the value information is retrieved; The logic of the rhetorical question determines the corresponding index score by comparing the rhetorical question with the medical rules and logical sequence included in the standardized patient information
7. The method of claim 1, wherein the multiple rounds of dialogue include the diagnosis results of the doctor agent; and the evaluation indicators include: The second type of indicators used to examine the ability of physician agents to reason out diagnostic results; The second type of indicators includes at least one of diagnostic accuracy and diagnostic information amount; The diagnostic accuracy is determined by whether the diagnostic result is consistent with the standard diagnostic result included in the standardized patient information; The amount of diagnosis information is determined by the number of keyword matches between the diagnosis result and the standard diagnosis result.
 8. The method of claim 1, wherein the multiple rounds of dialogue include the treatment plan of the doctor agent; and the evaluation indicators include: The third category of indicators is used to examine the ability of doctors to provide treatment plans; The third category of indicators includes at least one of the accuracy of the treatment plan and the amount of treatment information; The accuracy of the treatment plan is determined by whether the treatment plan is consistent with the standard treatment plan included in the standardized patient information; The amount of treatment information is determined by the number of keyword matches between the treatment plan and the standard treatment plan. 9. The method according to claim 7 or 8, wherein the evaluation index further includes verification capability, which is determined by whether the rhetorical question covers each key information included in the standardized patient information. 10. The method according to claim 1, wherein the evaluation index comprises: The fourth category of indicators used to examine the ability of the doctor agent to fully understand the patient's situation is determined by the amount of retrieved value information. 11. The method according to claim 1, wherein the evaluation index comprises: The fifth category of indicators is used to examine the ability of the doctor's agent to make a diagnosis result in a multi-round dialogue through an appropriate number of dialogue rounds, which is determined by whether the number of dialogue rounds in the multi-round dialogue exceeds the standard number of rounds included in the standardized patient information. 12. The method of claim 1, wherein the method further comprises: Based at least on whether the value information is retrieved, it is determined whether the large language model has a hallucination problem. 13. The method of claim 12, wherein determining whether the large language model has a hallucination problem comprises: When the value information is not retrieved, it is determined that the large language model has a hallucination problem; or, When the diagnosis results given by the doctor agent in the multiple rounds of dialogue are inconsistent with the standard diagnosis results included in the standardized patient information, it is determined that the large language model has a hallucination problem. 14. An evaluation device for a large language model as a doctor agent, the device comprising An acquisition unit, used for acquiring an initialization patient inquiry statement of a patient agent from pre-built standardized patient information; An input unit, used for inputting the initialization patient query sentence acquired by the acquisition unit into the large language model to obtain a counter-question of the doctor agent; An extraction unit, used for extracting key information representing a project name in clinical medicine from the rhetorical question obtained by the input unit; a retrieval unit, configured to retrieve corresponding value information from the standardized patient information according to the key information obtained by the extraction unit; The input unit is further configured to, when the retrieval unit retrieves the value information, input the value information as the patient agent's answer to the rhetorical question into the large language model again to achieve a multi-round dialogue; A scoring unit is used to determine the index scores of the multiple rounds of dialogue corresponding to each evaluation index, and the index scores are used to measure the ability of the large language model in clinical diagnosis and treatment. 15. A computer-readable storage medium having a computer program stored thereon, which, when executed in a computer, causes the computer to execute the method according to any one of claims 1 to 13. 16. A computing device comprising a memory and a processor, wherein the memory stores executable codes, and when the processor executes the executable codes, the method according to any one of claims 1 to 13 is implemented.
Searcher’s Comment
The cited prior art details a method for evaluating a large language model as a doctor agent, which is similar to the proposed invention.
Feature 1 (System and method for measuring the overall trustworthiness of medical large language models based on Consensus Reasoning and Epistemic Uncertainty, consistency between the reasoning and diagnosis of LLM, and monitoring of tests and prescriptions): 
The method of claim 1, wherein the multiple rounds of dialogue include the diagnosis results of the doctor agent; and the evaluation indicators include: The second type of indicators used to examine the ability of physician agents to reason out diagnostic results; The second type of indicators includes at least one of diagnostic accuracy and diagnostic information amount; The diagnostic accuracy is determined by whether the diagnostic result is consistent with the standard diagnostic result included in the standardized patient information; The amount of diagnosis information is determined by the number of keyword matches between the diagnosis result and the standard diagnosis result.
The highlighted steps of doctor agent evaluation includes assessing the reasoning capability of physician agent to provide diagnostic result and determining the diagnostic accuracy and diagnosis information which is similar to the proposed invention.
Inventor’s differentiating points / additional information is important to conclude relevance of the subject prior art to the proposed invention.
Inventor’s Comment
Feature 1 (System and method for measuring the overall trustworthiness of medical large language models based on Consensus Reasoning and Epistemic Uncertainty, consistency between the reasoning and diagnosis of LLM, and monitoring of tests and prescriptions): 
