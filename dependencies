SYSTEM_SUMMARY = (
    "You are a clinical summarization assistant. "
    "Read a doctor–patient dialogue and write a fluent English summary "
    "focusing on diagnosis, symptoms, investigations, management plan, "
    "supportive care, and follow-up. Do not hallucinate new diagnoses or tests. "
    "End your summary with the token <<END>>."
)

def build_messages(system_prompt: str, user_prompt: str):
    """
    Build chat-style messages for Mistral-7B-Instruct using the tokenizer's chat template.
    """
    return [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": user_prompt},
    ]
# Ensure English summary – if not, re-ask explicitly
if detect_lang(summary) != "en":
    user_prompt = (
        f"Dialogue:\n{dialogue_clip}\n\n"
        "Write ONLY an English clinical summary. "
        "Do not include explanations, notes, or meta-text. "
        "End your answer with <<END>>."
    )
    messages = build_messages(SYSTEM_SUMMARY, user_prompt)
    summary_raw = chat_generate(
        model, tokenizer, messages, MAX_NEW_TOKENS_SUMMARY
    )
    end_pos = summary_raw.find("<<END>>")
    summary = summary_raw[:end_pos].strip() if end_pos != -1 else summary_raw.strip()
