U/usr/bin/python: No module named transformers.convert_old_checkpoints_to_safetensors

�trainable params: 1,089,536 || all params: 1,544,803,840 || trainable%: 0.07052908413277896
[convert] ⚙️ Converting .bin → .safetensors in /workspace/data/KZ_2117574/qwen15b_lora_multilingual/checkpoint-11000 …
[convert] ⚠️ Conversion failed: Command '['python', '-m', 'transformers.convert_old_checkpoints_to_safetensors', '--model_name_or_path', '/workspace/data/KZ_2117574/qwen15b_lora_multilingual/checkpoint-11000', '--output_dir', '/workspace/data/KZ_2117574/qwen15b_lora_multilingual/checkpoint-11000']' returned non-zero exit status 1.
[Resuming from /workspace/data/KZ_2117574/qwen15b_lora_multilingual/checkpoint-11000]

lTraceback (most recent call last):
  File "/workspace/table-to-text-flan-t5/qwen.py", line 305, in <module>

P    main()
  File "/workspace/table-to-text-flan-t5/qwen.py", line 293, in main

�    trainer.train(resume_from_checkpoint=ckpt)
  File "/usr/local/lib/python3.10/dist-packages/transformers/trainer.py", line 2325, in train

�    return inner_training_loop(
  File "/usr/local/lib/python3.10/dist-packages/transformers/trainer.py", line 2510, in _inner_training_loop

�    self._load_optimizer_and_scheduler(resume_from_checkpoint)
  File "/usr/local/lib/python3.10/dist-packages/transformers/trainer.py", line 3589, in _load_optimizer_and_scheduler

�    check_torch_load_is_safe()
  File "/usr/local/lib/python3.10/dist-packages/transformers/utils/import_utils.py", line 1647, in check_torch_load_is_safe

k    raise ValueError(
ValueError: Due to a serious vulnerability issue in `torch.load`, even with `weights_only=True`, we now require users to upgrade torch to at least v2.6 in order to use the function. This version restriction does not apply when loading files with safetensors.
See the vulnerability report here https://nvd.nist.gov/vuln/detail/CVE-2025-32434
