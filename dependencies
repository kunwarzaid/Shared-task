• Diagnostic accuracy alone does not guarantee trustworthy medical AI  

• Trust emerges when reasoning, uncertainty, and safety are made visible  

• Multi-agent consensus exposes epistemic uncertainty  

• Real-time safety agents prevent silent clinical failures  

• Trust-X transforms opaque predictions into auditable, accountable reasoning  

• Trustworthy AI must be measured by how it reasons, not just what it predicts  
