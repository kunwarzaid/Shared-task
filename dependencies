	3.  Reasoning Aware Self-Consistency: Leveraging Reasoning Paths for Efficient LLM Sampling
BIBLIOGRAPHIC INFORMATION
Title	Reasoning Aware Self-Consistency: Leveraging Reasoning Paths for Efficient LLM Sampling 
Author	Guangya Wan, Yuqi Wu, Jie Chen, Sheng Li
Publication Date	4 Feb 2025
Abstract
Self-Consistency mitigates hallucinations in Large Language Models (LLMs) by sampling multiple reasoning paths,but it lacks a systematic approach to determine the optimal number of samples or select the most faithful rationale. To address this limitation, we introduce Reasoning-Aware Self-Consistency (RASC), a novel framework that enhances sampling efficiency and reasoning faithfulness by dynamically evaluating both outputs and rationales. RASC assesses the quality of reasoning and the consistency of answers for each generated sample, using these assessments to guide early stopping decisions and rationale selection. The framework employs criteria-based stopping and weighted majority voting, enabling more informed choices on when to halt sampling and which rationale to select. Our comprehensive experiments across diverse question-answering datasets demonstrate that RASC outperforms existing methods, reducing sample usage by approximately 70% while maintaining accuracy. Moreover, RASC facilitates the selection of high-fidelity rationales, thereby improving the faithfulness of LLM outputs. Our approach effectively addresses the efficiency-accuracy trade-off in LLM reasoning tasks, offering a new perspective for more nuanced, faithful, and effective utilization of LLMs in resource-constrained environments.
Relevant Text
We propose ReasoningAware Self-Consistency (RASC), a framework that optimizes sampling efficiency while maintaining accuracy by evaluating both reasoning paths and answers. RASC introduces a sufficiency scoring function that combines reasoning quality and answer consistency features, mapped to a continuous score via an optimized classifier. The framework employs a dynamic sampling process with a buffer of high-quality samples, stopping when a predefined capacity is reached. Finally, RASC uses weighted majority voting based on the scores to select the final answer and most faithful reasoning path. This approach integrates reasoning evaluation into the self-consistency process, offering a more faithful and computationally efficient method for complex question-answering tasks in LLMs.
 
 
 

Searcher’s Comment
The cited NPL optimizes sampling efficiency by evaluating both reasoning paths and answers which is similar to the Reasoning–Diagnosis Consistency of the proposed invention.
Feature 1 (System and method for measuring the overall trustworthiness of medical large language models based on Consensus Reasoning and Epistemic Uncertainty, consistency between the reasoning and diagnosis of LLM, and monitoring of tests and prescriptions):  The evaluation of reasoning path and answers map with the Reasoning–Diagnosis Consistency which   measure how well an agent’s explanation aligns with its final answer. However the prior art does not measures Operational Safety Index (OSI) or Consensus Disagreement Rate(CDR).
Inventor’s differentiating points / additional information is important to conclude relevance of the subject prior art to the proposed invention.
Inventor’s Comment
Feature 1 (System and method for measuring the overall trustworthiness of medical large language models based on Consensus Reasoning and Epistemic Uncertainty, consistency between the reasoning and diagnosis of LLM, and monitoring of tests and prescriptions): 
